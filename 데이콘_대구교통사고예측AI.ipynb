{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZpSpQSKehxt",
        "outputId": "a5934712-af92-4b2a-a778-09b19eb0dba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3uRE1wRkfGSx",
        "outputId": "d1bf1b39-cf08-42b2-ae9c-e03c88310873"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!pip install workalendar\\n!pip install lightgbm==3.3.2\\n!pip install category_encoders\\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "!pip install workalendar\n",
        "!pip install lightgbm==3.3.2\n",
        "!pip install category_encoders\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9M6aEsgAqLBC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pandas import Timestamp, DateOffset\n",
        "from workalendar.asia import SouthKorea\n",
        "\n",
        "# matplotlib 폰트설정\n",
        "# plt.rc('font', family='NanumGothicOTF') # For MacOS\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] ='Malgun Gothic'\n",
        "plt.rcParams['axes.unicode_minus'] =False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fead32lJqBd4"
      },
      "outputs": [],
      "source": [
        "train=pd.read_csv(\"/content/drive/MyDrive/BITAmin/DaconData/train.csv\")\n",
        "test=pd.read_csv(\"/content/drive/MyDrive/BITAmin/DaconData/test.csv\")\n",
        "ss=pd.read_csv(\"/content/drive/MyDrive/BITAmin/DaconData/sample_submission.csv\")\n",
        "acc=pd.read_csv(\"/content/drive/MyDrive/BITAmin/DaconData/external_open/countrywide_accident.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "TBz0WSBZqTJl"
      },
      "outputs": [],
      "source": [
        "#이상치 제거\n",
        "train=train[train[\"ECLO\"]<=20]\n",
        "acc=acc[acc[\"ECLO\"]<=20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GrcA4Yb1q6r8"
      },
      "outputs": [],
      "source": [
        "#데이터 분리\n",
        "train1=train[train[\"사고유형\"]==\"차량단독\"]\n",
        "train2=train[train[\"사고유형\"]==\"차대차\"]\n",
        "train3=train[train[\"사고유형\"]==\"차대사람\"]\n",
        "\n",
        "test1=test[test[\"사고유형\"]==\"차량단독\"]\n",
        "test2=test[test[\"사고유형\"]==\"차대차\"]\n",
        "test3=test[test[\"사고유형\"]==\"차대사람\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "COdxoazYq8PU"
      },
      "outputs": [],
      "source": [
        "all_car_alone=acc[acc[\"사고유형\"]==\"차량단독\"]\n",
        "c_to_c=acc[acc[\"사고유형\"]==\"차대차\"]\n",
        "c_to_h=acc[acc[\"사고유형\"]==\"차대사람\"]\n",
        "train1=pd.concat([train1,all_car_alone])\n",
        "train2=pd.concat([train2,c_to_c])\n",
        "train3=pd.concat([train3,c_to_h])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IIethP9oq9Jv"
      },
      "outputs": [],
      "source": [
        "# target 변수 지정\n",
        "y_train1 = train1['ECLO']\n",
        "y_train2 = train2['ECLO']\n",
        "y_train3 = train3['ECLO']\n",
        "# train, test 데이터간 컬럼 동기화\n",
        "cols = test1.columns\n",
        "X_train1 = train1[cols]\n",
        "X_test1 = test1\n",
        "\n",
        "X_train2 = train2[cols]\n",
        "X_test2 = test2\n",
        "\n",
        "X_train3 = train3[cols]\n",
        "\n",
        "X_test3 = test3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "hLzrUkVyq-j4"
      },
      "outputs": [],
      "source": [
        "def feat_eng1(df):\n",
        "  # == ID 패스 ==\n",
        "\n",
        "  # == 사고일시 ==\n",
        "  time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})'\n",
        "\n",
        "  df[['연', '월', '일', '시간']] = df['사고일시'].str.extract(time_pattern)\n",
        "  df[['연', '월', '일', '시간']] = df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다\n",
        "\n",
        "  # = 공휴일 column 추가 =\n",
        "  def is_holiday(year, month, day):\n",
        "    cal = SouthKorea()\n",
        "    return cal.is_holiday(Timestamp(year, month, day))\n",
        "\n",
        "  def classify_day(year, month, day):\n",
        "    date = Timestamp(year, month, day)\n",
        "    if date.dayofweek < 5 and not is_holiday(year, month, day):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "  df['Holiday'] = df.apply(lambda row: classify_day(row['연'], row['월'], row['일']), axis=1)\n",
        "  df.drop(columns=['사고일시','일','연','요일'], inplace = True) # 정보 추출이 완료된 '사고일시','일','요일','연' 컬럼은 제거합니다\n",
        "\n",
        "\n",
        "  # == 봄, 여름, 가을, 겨울, 기상학적으로 구분함 ==\n",
        "  def categorize_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "      return '봄'\n",
        "\n",
        "    elif month in [6, 7, 8]:\n",
        "      return '여름'\n",
        "\n",
        "    elif month in [9, 10, 11]:\n",
        "      return '가을'\n",
        "\n",
        "    else:\n",
        "      return '겨울'\n",
        "\n",
        "  df['계절'] = df['월'].apply(categorize_season)\n",
        "\n",
        "  # == 출 퇴근 시간(공휴일까지 고려) ==  평일에는 7~9, 18~20시까지 출퇴근, 공휴일에는 18~22시까지 교통량 증가로 확인\n",
        "  def rush_hour(hour, holiday):\n",
        "      if holiday == 1 or (holiday == 0 and hour in [18, 19, 20, 21, 22]):\n",
        "          return \"출퇴근\"\n",
        "      else:\n",
        "          return \"노출퇴근\"\n",
        "\n",
        "  df['출퇴근'] = df.apply(lambda row: rush_hour(row['시간'], row['Holiday']), axis=1)\n",
        "\n",
        "\n",
        "  # == 시군구, 도시는 버리지 않음 ==\n",
        "  location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "  df[['도시', '구', '동']] = df['시군구'].str.extract(location_pattern)\n",
        "  df.drop(columns=['시군구', '도시', '사고유형'], inplace = True)\n",
        "\n",
        "  # == 도로형태 == -> 분리하지말고 target encoding\n",
        "\n",
        "  # == 기상상태, 노면상태, 계절 -> 원핫인코딩 ==\n",
        "  df = pd.get_dummies(df, columns = ['기상상태', '노면상태', '계절', '출퇴근'])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bVrczrTaq-9-"
      },
      "outputs": [],
      "source": [
        "def feat_eng2(df):\n",
        "  # == ID 패스 ==\n",
        "\n",
        "  # == 사고일시 ==\n",
        "  time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})'\n",
        "\n",
        "  df[['연', '월', '일', '시간']] = df['사고일시'].str.extract(time_pattern)\n",
        "  df[['연', '월', '일', '시간']] = df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다\n",
        "\n",
        "  # = 공휴일 column 추가 =\n",
        "  def is_holiday(year, month, day):\n",
        "    cal = SouthKorea()\n",
        "    return cal.is_holiday(Timestamp(year, month, day))\n",
        "\n",
        "  def classify_day(year, month, day):\n",
        "    date = Timestamp(year, month, day)\n",
        "    if date.dayofweek < 5 and not is_holiday(year, month, day):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "  df['Holiday'] = df.apply(lambda row: classify_day(row['연'], row['월'], row['일']), axis=1)\n",
        "  df.drop(columns=['사고일시','일','연','요일'], inplace = True) # 정보 추출이 완료된 '사고일시','일','요일','연' 컬럼은 제거합니다\n",
        "\n",
        "\n",
        "  # == 봄, 여름, 가을, 겨울, 기상학적으로 구분함 ==\n",
        "  def categorize_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "      return '봄'\n",
        "\n",
        "    elif month in [6, 7, 8]:\n",
        "      return '여름'\n",
        "\n",
        "    elif month in [9, 10, 11]:\n",
        "      return '가을'\n",
        "\n",
        "    else:\n",
        "      return '겨울'\n",
        "\n",
        "  df['계절'] = df['월'].apply(categorize_season)\n",
        "\n",
        "  # == 출 퇴근 시간(공휴일까지 고려) ==  평일에는 7~9, 18~20시까지 출퇴근, 공휴일에는 18~22시까지 교통량 증가로 확인\n",
        "  def rush_hour(hour, holiday):\n",
        "      if holiday == 1 or (holiday == 0 and hour in [18, 19, 20, 21, 22]):\n",
        "          return \"출퇴근\"\n",
        "      else:\n",
        "          return \"노출퇴근\"\n",
        "\n",
        "  df['출퇴근'] = df.apply(lambda row: rush_hour(row['시간'], row['Holiday']), axis=1)\n",
        "\n",
        "\n",
        "  # == 시군구, 도시는 버리지 않음 ==\n",
        "  location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "  df[['도시', '구', '동']] = df['시군구'].str.extract(location_pattern)\n",
        "  df.drop(columns=['시군구', '도시', '사고유형'], inplace = True)\n",
        "\n",
        "  # == 도로형태 == -> 분리하지말고 target encoding\n",
        "\n",
        "  # == 기상상태, 노면상태, 계절 -> 원핫인코딩 ==\n",
        "  df = pd.get_dummies(df, columns = ['기상상태', '노면상태', '계절', '출퇴근'])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "npAL6aUOrBr2"
      },
      "outputs": [],
      "source": [
        "def feat_eng3(df):\n",
        "  # == ID 패스 ==\n",
        "\n",
        "  # == 사고일시 ==\n",
        "  time_pattern = r'(\\d{4})-(\\d{1,2})-(\\d{1,2}) (\\d{1,2})'\n",
        "\n",
        "  df[['연', '월', '일', '시간']] = df['사고일시'].str.extract(time_pattern)\n",
        "  df[['연', '월', '일', '시간']] = df[['연', '월', '일', '시간']].apply(pd.to_numeric) # 추출된 문자열을 수치화해줍니다\n",
        "\n",
        "  # = 공휴일 column 추가 =\n",
        "  def is_holiday(year, month, day):\n",
        "    cal = SouthKorea()\n",
        "    return cal.is_holiday(Timestamp(year, month, day))\n",
        "\n",
        "  def classify_day(year, month, day):\n",
        "    date = Timestamp(year, month, day)\n",
        "    if date.dayofweek < 5 and not is_holiday(year, month, day):\n",
        "      return 0\n",
        "    else:\n",
        "      return 1\n",
        "\n",
        "  df['Holiday'] = df.apply(lambda row: classify_day(row['연'], row['월'], row['일']), axis=1)\n",
        "  df.drop(columns=['사고일시','일','연','요일'], inplace = True) # 정보 추출이 완료된 '사고일시','일','요일','연' 컬럼은 제거합니다\n",
        "\n",
        "\n",
        "  # == 봄, 여름, 가을, 겨울, 기상학적으로 구분함 ==\n",
        "  def categorize_season(month):\n",
        "    if month in [3, 4, 5]:\n",
        "      return '봄'\n",
        "\n",
        "    elif month in [6, 7, 8]:\n",
        "      return '여름'\n",
        "\n",
        "    elif month in [9, 10, 11]:\n",
        "      return '가을'\n",
        "\n",
        "    else:\n",
        "      return '겨울'\n",
        "\n",
        "  df['계절'] = df['월'].apply(categorize_season)\n",
        "\n",
        "  # == 출 퇴근 시간(공휴일까지 고려) ==  평일에는 7~9, 18~20시까지 출퇴근, 공휴일에는 18~22시까지 교통량 증가로 확인\n",
        "  def rush_hour(hour, holiday):\n",
        "      if holiday == 1 or (holiday == 0 and hour in [18, 19, 20, 21, 22]):\n",
        "          return \"출퇴근\"\n",
        "      else:\n",
        "          return \"노출퇴근\"\n",
        "\n",
        "  df['출퇴근'] = df.apply(lambda row: rush_hour(row['시간'], row['Holiday']), axis=1)\n",
        "\n",
        "\n",
        "  # == 시군구, 도시는 버리지 않음 ==\n",
        "  location_pattern = r'(\\S+) (\\S+) (\\S+)'\n",
        "\n",
        "  df[['도시', '구', '동']] = df['시군구'].str.extract(location_pattern)\n",
        "  df.drop(columns=['시군구', '도시', '사고유형'], inplace = True)\n",
        "\n",
        "  # == 도로형태 == -> 분리하지말고 target encoding\n",
        "\n",
        "  # == 기상상태, 노면상태, 계절 -> 원핫인코딩 ==\n",
        "  df = pd.get_dummies(df, columns = ['기상상태', '노면상태', '계절', '출퇴근'])\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Fd53xc_mrDGx"
      },
      "outputs": [],
      "source": [
        "X_train_eng1 = feat_eng1(X_train1)\n",
        "X_test_eng1 = feat_eng1(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "kKnyC8PRrD0_"
      },
      "outputs": [],
      "source": [
        "X_train_eng2 = feat_eng2(X_train2)\n",
        "X_test_eng2 = feat_eng2(X_test2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "vzwlphfIrEce"
      },
      "outputs": [],
      "source": [
        "X_train_eng3 = feat_eng3(X_train3)\n",
        "X_test_eng3 = feat_eng3(X_test3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "8DS_f19ArFZt"
      },
      "outputs": [],
      "source": [
        "list1=[]\n",
        "list2=[]\n",
        "list3=[]\n",
        "del_ID1=[]\n",
        "del_ID2=[]\n",
        "del_ID3=[]\n",
        "for i in X_train_eng1.columns:\n",
        "    if i not in X_test_eng1.columns :\n",
        "        list1.append(i)\n",
        "for i in list1:\n",
        "    for j in X_train_eng1[X_train_eng1[i]==1][\"ID\"] :\n",
        "        del_ID1.append(j)\n",
        "    X_train_eng1=X_train_eng1[X_train_eng1[i]==0].drop(i, axis=1)\n",
        "X_train_eng1.sort_index(axis=1,inplace=True)\n",
        "\n",
        "for i in X_train_eng2.columns:\n",
        "    if i not in X_test_eng2.columns:\n",
        "        list2.append(i)\n",
        "for i in list2:\n",
        "    for j in X_train_eng2[X_train_eng2[i]==1][\"ID\"] :\n",
        "        del_ID2.append(j)\n",
        "    X_train_eng2=X_train_eng2[X_train_eng2[i]==0].drop(i, axis=1)\n",
        "X_train_eng2.sort_index(axis=1,inplace=True)\n",
        "\n",
        "for i in X_train_eng3.columns:\n",
        "    if i not in X_test_eng3.columns:\n",
        "        list3.append(i)\n",
        "for i in list3:\n",
        "    for j in X_train_eng3[X_train_eng3[i]==1][\"ID\"] :\n",
        "        del_ID3.append(j)\n",
        "    X_train_eng3=X_train_eng3[X_train_eng3[i]==0].drop(i, axis=1)\n",
        "X_train_eng3.sort_index(axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "JpLHYpWBrGaO"
      },
      "outputs": [],
      "source": [
        "X_train_eng1.drop(\"ID\", axis=1, inplace=True)\n",
        "X_train_eng2.drop(\"ID\", axis=1, inplace=True)\n",
        "X_train_eng3.drop(\"ID\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "heQgSgAfrG6c"
      },
      "outputs": [],
      "source": [
        "for i in X_test_eng1.columns:\n",
        "    if i not in X_train_eng1.columns:\n",
        "        X_test_eng1.drop(i, axis=1, inplace=True)\n",
        "X_test_eng1.sort_index(axis=1, inplace=True)\n",
        "\n",
        "for i in X_test_eng2.columns:\n",
        "    if i not in X_train_eng2.columns:\n",
        "        X_test_eng2.drop(i, axis=1, inplace=True)\n",
        "X_test_eng2.sort_index(axis=1, inplace=True)\n",
        "\n",
        "for i in X_test_eng3.columns:\n",
        "    if i not in X_train_eng3.columns:\n",
        "        X_test_eng3.drop(i, axis=1, inplace=True)\n",
        "X_test_eng3.sort_index(axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "dEkfbuc6rInm"
      },
      "outputs": [],
      "source": [
        "def rmsle(y,pred) :\n",
        "    log_y=np.log1p(y)\n",
        "    log_pred=np.log1p(pred)\n",
        "    squared_error = (log_y - log_pred) ** 2\n",
        "    rmsle=np.sqrt(np.mean(squared_error))\n",
        "    return rmsle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "K0yi8LwJrJRO"
      },
      "outputs": [],
      "source": [
        "y_train1 = train1[~(train1[\"ID\"].isin(del_ID1))]['ECLO']\n",
        "y_train2 = train2[~(train2[\"ID\"].isin(del_ID2))]['ECLO']\n",
        "y_train3 = train3[~(train3[\"ID\"].isin(del_ID3))]['ECLO']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RBhuPNzdrKE2",
        "outputId": "19991557-fe34-4e6f-d911-0852e3cf0dfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['구', '도로형태', '동']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['구', '도로형태', '동']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "['구', '도로형태', '동']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from category_encoders.target_encoder import TargetEncoder\n",
        "\n",
        "#\n",
        "categorical_features = list(X_train_eng1.dtypes[X_train_eng1.dtypes == \"object\"].index)\n",
        "# categorical_features.append(\"월\")\n",
        "# categorical_features.append(\"시\")\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = TargetEncoder(cols=[i])\n",
        "    X_train_eng1[i] = le.fit_transform(X_train_eng1[i], y_train1)\n",
        "    X_test_eng1[i] = le.transform(X_test_eng1[i])\n",
        "\n",
        "categorical_features = list(X_train_eng2.dtypes[X_train_eng2.dtypes == \"object\"].index)\n",
        "# categorical_features.append(\"월\")\n",
        "# categorical_features.append(\"시\")\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "\n",
        "for i in categorical_features:\n",
        "    le = TargetEncoder(cols=[i])\n",
        "    X_train_eng2[i] = le.fit_transform(X_train_eng2[i], y_train2)\n",
        "    X_test_eng2[i] = le.transform(X_test_eng2[i])\n",
        "\n",
        "categorical_features = list(X_train_eng3.dtypes[X_train_eng3.dtypes == \"object\"].index)\n",
        "# 추출된 문자열 변수 확인\n",
        "display(categorical_features)\n",
        "# categorical_features.append(\"월\")\n",
        "# categorical_features.append(\"시\")\n",
        "for i in categorical_features:\n",
        "    le = TargetEncoder(cols=[i])\n",
        "    X_train_eng3[i] = le.fit_transform(X_train_eng3[i], y_train3)\n",
        "    X_test_eng3[i] = le.transform(X_test_eng3[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "L2_lPW4lrMOa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMRegressor\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "import numpy as np\n",
        "\n",
        "def rmsle(y, pred):\n",
        "    log_y = np.log1p(y)\n",
        "    log_pred = np.log1p(pred)\n",
        "    squared_error = (log_y - log_pred) ** 2\n",
        "    rmsle = np.sqrt(np.mean(squared_error))\n",
        "    return rmsle\n",
        "\n",
        "def custom_rmsle(y_true, y_pred):\n",
        "    rmsle_value = float(rmsle(y_true, y_pred))\n",
        "    return 'RMSLE', rmsle_value, False\n",
        "\n",
        "# Log transformation of target variable\n",
        "y_train_log_total1 = np.log1p(y_train1)\n",
        "X_train1, X_test1, y_train_log1, y_test_log1 = train_test_split(X_train_eng1, y_train_log_total1, test_size=0.2, random_state=42)\n",
        "X_tr1, X_val1, y_tr_log1, y_val_log1 = train_test_split(X_train1, y_train_log1, test_size=0.3, random_state=42)\n",
        "\n",
        "y_train_log_total2 = np.log1p(y_train2)\n",
        "X_train2, X_test2, y_train_log2, y_test_log2 = train_test_split(X_train_eng2, y_train_log_total2, test_size=0.2, random_state=42)\n",
        "X_tr2, X_val2, y_tr_log2, y_val_log2 = train_test_split(X_train2, y_train_log2, test_size=0.3, random_state=42)\n",
        "\n",
        "y_train_log_total3 = np.log1p(y_train3)\n",
        "X_train3, X_test3, y_train_log3, y_test_log3 = train_test_split(X_train_eng3, y_train_log_total3, test_size=0.2, random_state=42)\n",
        "X_tr3, X_val3, y_tr_log3, y_val_log3 = train_test_split(X_train3, y_train_log3, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmEUEP3YefYo",
        "outputId": "b0240310-4f0c-4641-decb-a178ce9e3098"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the objective function for hyperopt\n",
        "def objective(params):\n",
        "    lgbm_params = {\n",
        "        'learning_rate': params['learning_rate'],\n",
        "        'n_estimators': int(params['n_estimators']),\n",
        "        'num_leaves': int(params['num_leaves']),\n",
        "        'max_depth': int(params['max_depth']),\n",
        "        'subsample': params['subsample'],\n",
        "        'colsample_bytree': params['colsample_bytree'],\n",
        "        'min_child_samples': int(params['min_child_samples']),\n",
        "        'reg_alpha': params['reg_alpha'],\n",
        "        'reg_lambda': params['reg_lambda'],\n",
        "        'min_split_gain': params['min_split_gain']\n",
        "    }\n",
        "    lgbm_model = LGBMRegressor(**lgbm_params, random_state=0, n_jobs = -1)\n",
        "\n",
        "    # 3개의 k-fold 방식으로 평가된 rmsle 지표를 담는 list\n",
        "    rmsle_list = []\n",
        "\n",
        "    # 3-fold k-fold 방식 적용\n",
        "    kf = KFold(n_splits=3)\n",
        "    for tr_index, val_index in kf.split(X_train1):\n",
        "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리\n",
        "        X_tr, y_log_tr = X_train1.iloc[tr_index], y_train_log_total1.iloc[tr_index]\n",
        "        X_val, y_log_val = X_train1.iloc[val_index], y_train_log_total1.iloc[val_index]\n",
        "\n",
        "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
        "        lgbm_model.fit(X_tr, y_log_tr, early_stopping_rounds=30, eval_metric= custom_rmsle,\n",
        "                       eval_set=[(X_tr, y_log_tr), (X_val, y_log_val)])\n",
        "        y_val_pred = np.expm1(lgbm_model.predict(X_val))\n",
        "        rmsle_val = rmsle(y_val_pred, np.expm1(y_log_val))\n",
        "        rmsle_list.append(rmsle_val)\n",
        "\n",
        "    # Return the mean rmsle as the loss\n",
        "    return np.mean(rmsle_list)\n",
        "\n",
        "\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "space1 = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 10, 100, 1),\n",
        "    'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.7, 1),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 20, 100, 1),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-9), np.log(1)),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-9), np.log(1)),\n",
        "    'min_split_gain': hp.loguniform('min_split_gain', np.log(1e-9), np.log(1))\n",
        "}\n",
        "\n",
        "# Create Trials object to store optimization results\n",
        "trials = Trials()\n",
        "\n",
        "# Run hyperopt optimization\n",
        "best1 = fmin(fn=objective, space=space1, algo=tpe.suggest, max_evals=100, trials=trials, rstate=np.random.default_rng(seed=30))\n",
        "print(best1)\n",
        "\n",
        "best_params1 = {\n",
        "    'learning_rate': best1[\"learning_rate\"],\n",
        "    'n_estimators': int(best1['n_estimators']),\n",
        "    'num_leaves': int(best1['num_leaves']),\n",
        "    'max_depth': int(best1['max_depth']),\n",
        "    'min_child_samples': int(best1['min_child_samples']),\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'subsample': best1['subsample'],\n",
        "    'colsample_bytree': best1['colsample_bytree'],\n",
        "    'reg_alpha': best1['reg_alpha'],\n",
        "    'reg_lambda': best1['reg_lambda'],\n",
        "    'min_split_gain': best1['min_split_gain']\n",
        "}\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuGrAsgEefYo",
        "outputId": "e6fcd270-eb06-4f8c-b87e-8127a5611ccc"
      },
      "outputs": [],
      "source": [
        "lg1 = LGBMRegressor(**best_params1, random_state=0, n_jobs = -1)\n",
        "\n",
        "lg1.fit(X_tr1, y_tr_log1, early_stopping_rounds=100, eval_metric=custom_rmsle, eval_set=[(X_tr1, y_tr_log1), (X_val1, y_val_log1)])\n",
        "\n",
        "y_test_pred_log1 = lg1.predict(X_test1)\n",
        "y_test_pred1 = np.expm1(y_test_pred_log1)\n",
        "\n",
        "rmsle_test = rmsle(np.expm1(y_test_log1), y_test_pred1)\n",
        "print('Test RMSLE:', rmsle_test)\n",
        "#Test RMSLE: 0.4747587094525547"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9pvnirWefYp",
        "outputId": "a8c68943-f583-4451-a2d1-c71aa601ec55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(493672, 23)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_eng2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DttAYbzDefYp",
        "outputId": "db1d6eef-8fa2-41d4-efb7-c52aa3375af6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the objective function for hyperopt\n",
        "def objective(params):\n",
        "    lgbm_params = {\n",
        "        'learning_rate': params['learning_rate'],\n",
        "        'n_estimators': int(params['n_estimators']),\n",
        "        'num_leaves': int(params['num_leaves']),\n",
        "        'max_depth': int(params['max_depth']),\n",
        "        'subsample': params['subsample'],\n",
        "        'colsample_bytree': params['colsample_bytree'],\n",
        "        'min_child_samples': int(params['min_child_samples']),\n",
        "        'reg_alpha': params['reg_alpha'],\n",
        "        'reg_lambda': params['reg_lambda'],\n",
        "        'min_split_gain': params['min_split_gain']\n",
        "    }\n",
        "    lgbm_model = LGBMRegressor(**lgbm_params, random_state=0, n_jobs = -1)\n",
        "\n",
        "    # 3개의 k-fold 방식으로 평가된 rmsle 지표를 담는 list\n",
        "    rmsle_list = []\n",
        "\n",
        "    # 3-fold k-fold 방식 적용\n",
        "    kf = KFold(n_splits=3)\n",
        "    for tr_index, val_index in kf.split(X_train2):\n",
        "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리\n",
        "        X_tr, y_log_tr = X_train2.iloc[tr_index], y_train_log_total2.iloc[tr_index]\n",
        "        X_val, y_log_val = X_train2.iloc[val_index], y_train_log_total2.iloc[val_index]\n",
        "\n",
        "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
        "        lgbm_model.fit(X_tr, y_log_tr, early_stopping_rounds=30, eval_metric= custom_rmsle,\n",
        "                       eval_set=[(X_tr, y_log_tr), (X_val, y_log_val)])\n",
        "        y_val_pred = np.expm1(lgbm_model.predict(X_val))\n",
        "        rmsle_val = rmsle(y_val_pred, np.expm1(y_log_val))\n",
        "        rmsle_list.append(rmsle_val)\n",
        "\n",
        "    # Return the mean rmsle as the loss\n",
        "    return np.mean(rmsle_list)\n",
        "\n",
        "\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "space2 = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 1000, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 30, 200, 1),\n",
        "    'max_depth': hp.quniform('max_depth', 5, 50, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.7, 1),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 20, 200, 1),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-9), np.log(1)),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-9), np.log(1)),\n",
        "    'min_split_gain': hp.loguniform('min_split_gain', np.log(1e-9), np.log(1))\n",
        "}\n",
        "\n",
        "# Create Trials object to store optimization results\n",
        "trials = Trials()\n",
        "\n",
        "# Run hyperopt optimization\n",
        "best2 = fmin(fn=objective, space=space2, algo=tpe.suggest, max_evals=200, trials=trials, rstate=np.random.default_rng(seed=30))\n",
        "print(best2)\n",
        "\n",
        "best_params2 = {\n",
        "    'learning_rate': best2[\"learning_rate\"],\n",
        "    'n_estimators': int(best2['n_estimators']),\n",
        "    'num_leaves': int(best2['num_leaves']),\n",
        "    'max_depth': int(best2['max_depth']),\n",
        "    'min_child_samples': int(best2['min_child_samples']),\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'subsample': best2['subsample'],\n",
        "    'colsample_bytree': best2['colsample_bytree'],\n",
        "    'reg_alpha': best2['reg_alpha'],\n",
        "    'reg_lambda': best2['reg_lambda'],\n",
        "    'min_split_gain': best2['min_split_gain']\n",
        "}\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYuW4_M_efYp",
        "outputId": "55c3ef39-8c77-4c3c-b5e4-2470be88773a"
      },
      "outputs": [],
      "source": [
        "lg2 = LGBMRegressor(**best_params2, random_state=0, n_jobs = -1)\n",
        "\n",
        "lg2.fit(X_tr2, y_tr_log2, early_stopping_rounds=100, eval_metric=custom_rmsle, eval_set=[(X_tr2, y_tr_log2), (X_val2, y_val_log2)])\n",
        "\n",
        "y_test_pred_log2 = lg2.predict(X_test2)\n",
        "y_test_pred2 = np.expm1(y_test_pred_log2)\n",
        "\n",
        "rmsle_test = rmsle(np.expm1(y_test_log2), y_test_pred2)\n",
        "print('Test RMSLE:', rmsle_test)\n",
        "#Test RMSLE: 0.4747587094525547"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtHBLCl8efYp",
        "outputId": "ad062bd7-b84f-4600-d0b6-0314a6c24771"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(117176, 20)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_eng3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYs6mU6refYp",
        "outputId": "7badeec6-01db-48ed-8196-3c7122d66111"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Define the objective function for hyperopt\n",
        "def objective(params):\n",
        "    lgbm_params = {\n",
        "        'learning_rate': params['learning_rate'],\n",
        "        'n_estimators': int(params['n_estimators']),\n",
        "        'num_leaves': int(params['num_leaves']),\n",
        "        'max_depth': int(params['max_depth']),\n",
        "        'subsample': params['subsample'],\n",
        "        'colsample_bytree': params['colsample_bytree'],\n",
        "        'min_child_samples': int(params['min_child_samples']),\n",
        "        'reg_alpha': params['reg_alpha'],\n",
        "        'reg_lambda': params['reg_lambda'],\n",
        "        'min_split_gain': params['min_split_gain']\n",
        "    }\n",
        "    lgbm_model = LGBMRegressor(**lgbm_params, random_state=0, n_jobs = -1)\n",
        "\n",
        "    # 3개의 k-fold 방식으로 평가된 rmsle 지표를 담는 list\n",
        "    rmsle_list = []\n",
        "\n",
        "    # 3-fold k-fold 방식 적용\n",
        "    kf = KFold(n_splits=3)\n",
        "    for tr_index, val_index in kf.split(X_train3):\n",
        "        # kf.split(X_train)으로 추출된 학습과 검증 index값으로 학습과 검증 데이터 세트 분리\n",
        "        X_tr, y_log_tr = X_train3.iloc[tr_index], y_train_log_total3.iloc[tr_index]\n",
        "        X_val, y_log_val = X_train3.iloc[val_index], y_train_log_total3.iloc[val_index]\n",
        "\n",
        "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행.\n",
        "        lgbm_model.fit(X_tr, y_log_tr, early_stopping_rounds=30, eval_metric= custom_rmsle,\n",
        "                       eval_set=[(X_tr, y_log_tr), (X_val, y_log_val)])\n",
        "        y_val_pred = np.expm1(lgbm_model.predict(X_val))\n",
        "        rmsle_val = rmsle(y_val_pred, np.expm1(y_log_val))\n",
        "        rmsle_list.append(rmsle_val)\n",
        "\n",
        "    # Return the mean rmsle as the loss\n",
        "    return np.mean(rmsle_list)\n",
        "\n",
        "\n",
        "\n",
        "# Define the search space for hyperparameters\n",
        "space3 = {\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 750, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
        "    'max_depth': hp.quniform('max_depth', 5, 30, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.7, 1),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 20, 150, 1),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-9), np.log(1)),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-9), np.log(1)),\n",
        "    'min_split_gain': hp.loguniform('min_split_gain', np.log(1e-9), np.log(1))\n",
        "}\n",
        "\n",
        "# Create Trials object to store optimization results\n",
        "trials = Trials()\n",
        "\n",
        "# Run hyperopt optimization\n",
        "best3 = fmin(fn=objective, space=space3, algo=tpe.suggest, max_evals=200, trials=trials, rstate=np.random.default_rng(seed=30))\n",
        "print(best3)\n",
        "\n",
        "best_params3 = {\n",
        "    'learning_rate': best3[\"learning_rate\"],\n",
        "    'n_estimators': int(best3['n_estimators']),\n",
        "    'num_leaves': int(best3['num_leaves']),\n",
        "    'max_depth': int(best3['max_depth']),\n",
        "    'min_child_samples': int(best3['min_child_samples']),\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'subsample': best3['subsample'],\n",
        "    'colsample_bytree': best3['colsample_bytree'],\n",
        "    'reg_alpha': best3['reg_alpha'],\n",
        "    'reg_lambda': best3['reg_lambda'],\n",
        "    'min_split_gain': best3['min_split_gain']\n",
        "}\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyqSKpQWefYp",
        "outputId": "e5ddd868-c153-4d62-f9b6-a31eabcbd12d"
      },
      "outputs": [],
      "source": [
        "lg3 = LGBMRegressor(**best_params3, random_state=0, n_jobs = -1)\n",
        "\n",
        "lg3.fit(X_tr3, y_tr_log3, early_stopping_rounds=100, eval_metric=custom_rmsle, eval_set=[(X_tr3, y_tr_log3), (X_val3, y_val_log3)])\n",
        "\n",
        "y_test_pred_log3 = lg3.predict(X_test3)\n",
        "y_test_pred3 = np.expm1(y_test_pred_log3)\n",
        "\n",
        "rmsle_test = rmsle(np.expm1(y_test_log3), y_test_pred3)\n",
        "print('Test RMSLE:', rmsle_test)\n",
        "#Test RMSLE: 0.4747587094525547"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "wcttIiGMrcAw"
      },
      "outputs": [],
      "source": [
        "y_pred1 = lg1.predict(X_test_eng1)\n",
        "y_pred1=np.expm1(y_pred1)\n",
        "\n",
        "y_pred2 = lg2.predict(X_test_eng2)\n",
        "y_pred2=np.expm1(y_pred2)\n",
        "\n",
        "y_pred3 = lg3.predict(X_test_eng3)\n",
        "y_pred3=np.expm1(y_pred3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "n8G3T_6grcqa"
      },
      "outputs": [],
      "source": [
        "test1[\"predict\"]=y_pred1\n",
        "test2[\"predict\"]=y_pred2\n",
        "test3[\"predict\"]=y_pred3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "RZ07N1yuefYq"
      },
      "outputs": [],
      "source": [
        "X_test=pd.merge(test, test1[[\"ID\",\"predict\"]], how=\"left\", on=\"ID\" )\n",
        "X_test[\"predict\"]=X_test[\"predict\"].fillna(0)\n",
        "X_test=pd.merge(X_test, test2[[\"ID\",\"predict\"]], how=\"left\", on=\"ID\" )\n",
        "X_test[\"predict_y\"]=X_test[\"predict_y\"].fillna(0)\n",
        "X_test=pd.merge(X_test, test3[[\"ID\",\"predict\"]], how=\"left\", on=\"ID\" )\n",
        "X_test[\"predict\"]=X_test[\"predict\"].fillna(0)\n",
        "X_test[\"predict\"]= X_test[\"predict_x\"]+X_test[\"predict_y\"]+X_test[\"predict\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cwv6Oc8qefYq",
        "outputId": "ff61ae88-d694-46d3-cc92-0662b3e2cca5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e8e0549-7553-4409-b2bf-577fde8267b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>ECLO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ACCIDENT_39609</td>\n",
              "      <td>3.883765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACCIDENT_39610</td>\n",
              "      <td>3.931548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ACCIDENT_39611</td>\n",
              "      <td>5.307546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACCIDENT_39612</td>\n",
              "      <td>4.674373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ACCIDENT_39613</td>\n",
              "      <td>4.801746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e8e0549-7553-4409-b2bf-577fde8267b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9e8e0549-7553-4409-b2bf-577fde8267b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9e8e0549-7553-4409-b2bf-577fde8267b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d3534479-7600-476c-b518-44a9060fcc55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3534479-7600-476c-b518-44a9060fcc55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d3534479-7600-476c-b518-44a9060fcc55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               ID      ECLO\n",
              "0  ACCIDENT_39609  3.883765\n",
              "1  ACCIDENT_39610  3.931548\n",
              "2  ACCIDENT_39611  5.307546\n",
              "3  ACCIDENT_39612  4.674373\n",
              "4  ACCIDENT_39613  4.801746"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss['ECLO'] = X_test[\"predict\"]\n",
        "ss.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "vlkXeqKZefYq"
      },
      "outputs": [],
      "source": [
        "OUTPUT_PATH = './output/'\n",
        "ss.to_csv(f'submission_bayesian.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
